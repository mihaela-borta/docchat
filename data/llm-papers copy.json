[
  {
    "tags": [
      "Multimodal",
      "Vision",
      "Internals"
    ],
    "title": "On the Hidden Mystery of OCR in Large Multimodal Models",
    "url": "https://arxiv.org/abs/2305.07895"
  },
  {
    "tags": [
      "Reasoning"
    ],
    "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
    "url": "https://arxiv.org/abs/2305.10601"
  },
  {
    "tags": [
      "UX/HCI",
      "Multimodal",
      "Prompting",
      "Vision"
    ],
    "title": "The Prompt Artists",
    "url": "https://arxiv.org/abs/2303.12253"
  },
  {
    "tags": [
      "Reasoning",
      "Amplification",
      "Tool Use"
    ],
    "title": "CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing",
    "url": "https://arxiv.org/abs/2305.11738"
  },
  {
    "tags": [
      "Scaling",
      "Critical"
    ],
    "title": "To Repeat or Not To Repeat: Insights from Scaling LLM under Token-Crisis",
    "url": "https://arxiv.org/abs/2305.13230"
  },
  {
    "tags": [
      "Scaling",
      "Vision"
    ],
    "title": "Getting ViT in Shape: Scaling Laws for Compute-Optimal Model Design",
    "url": "https://arxiv.org/abs/2305.13035"
  },
  {
    "tags": [
      "Dataset",
      "Reasoning"
    ],
    "title": "TheoremQA: A Theorem-driven Question Answering dataset",
    "url": "https://arxiv.org/abs/2305.12524"
  },
  {
    "tags": [
      "Evaluation",
      "Amplification"
    ],
    "title": "LM vs LM: ",
    "url": "https://arxiv.org/abs/2305.13281"
  },
  {
    "tags": [
      "Applications",
      "Code",
      "Prompting"
    ],
    "title": "How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings",
    "url": "https://arxiv.org/abs/2305.11853"
  },
  {
    "tags": [
      "Engineering"
    ],
    "title": "On-demand Container Loading in AWS Lambda",
    "url": "https://arxiv.org/abs/2305.13162"
  },
  {
    "tags": [
      "Reasoning",
      "Robotics",
      "Agency"
    ],
    "title": "Reasoning with Language Model is Planning with World Model",
    "url": "https://arxiv.org/abs/2305.14992"
  },
  {
    "tags": [
      "Scaling",
      "Critical"
    ],
    "title": "Scaling Data-Constrained Language Models",
    "url": "https://arxiv.org/abs/2305.16264"
  },
  {
    "tags": [
      "Tool Use",
      "Code",
      "Amplification",
      "Reasoning",
      "Agency"
    ],
    "title": "Language Models as Tool Makers",
    "url": "https://arxiv.org/abs/2305.17126"
  },
  {
    "tags": [
      "Finetuning",
      "Engineering"
    ],
    "title": "Fine-Tuning Language Models with Just Forward Passes",
    "url": "https://arxiv.org/abs/2305.17333"
  },
  {
    "tags": [
      "Evaluation",
      "Amplification",
      "Critical"
    ],
    "title": "Large Language Models are Not Fair Evaluators",
    "url": "https://arxiv.org/abs/2305.17926"
  },
  {
    "tags": [
      "Evaluation",
      "Reasoning"
    ],
    "title": "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance",
    "url": "https://arxiv.org/abs/2305.17306"
  },
  {
    "tags": [
      "Reasoning",
      "Internals",
      "Probabilistic Programs"
    ],
    "title": "Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective",
    "url": "https://arxiv.org/abs/2305.15408"
  },
  {
    "tags": [
      "Dataset",
      "Scaling"
    ],
    "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
    "url": "https://arxiv.org/abs/2306.01116"
  },
  {
    "tags": [
      "Internals"
    ],
    "title": "Learning Transformer Programs",
    "url": "https://arxiv.org/abs/2306.01128"
  },
  {
    "tags": [
      "Dataset",
      "Grounding"
    ],
    "title": "SWAG: A Large-Scale Adversarial Datasets for Grounded Commonsense Inference",
    "url": "https://arxiv.org/abs/1808.05326"
  },
  {
    "tags": [
      "Evaluation"
    ],
    "title": "Asking Crowdworkers to Write Entailment Examples: The Best of Bad Options",
    "url": "https://aclanthology.org/2020.aacl-main.68/"
  },
  {
    "tags": [
      "Evaluation",
      "Critical",
      "Philosophy"
    ],
    "title": "Benchmarking Machine Reading Comprehension: A Psychological Perspective",
    "url": "https://aclanthology.org/2021.eacl-main.137/"
  },
  {
    "tags": [
      "Evaluation",
      "Critical"
    ],
    "title": "Inherent disagreements in human textual inferences",
    "url": "https://aclanthology.org/Q19-1043/"
  },
  {
    "tags": [
      "Evaluation",
      "Feedback"
    ],
    "title": "The gamification of work: Lessons from crowdsourcing",
    "url": "https://trepo.tuni.fi/bitstream/handle/10024/118208/the_gamification_of_work_2018.pdf"
  },
  {
    "tags": [
      "Dataset"
    ],
    "title": "Natural Questions: A Benchmark for Question-Answering Research",
    "url": "https://aclanthology.org/Q19-1026/"
  },
  {
    "tags": [
      "Evaluation",
      "Critical",
      "Feedback"
    ],
    "title": "Utility is in the eye of the user: A critique of NLP leaderboards",
    "url": "https://arxiv.org/abs/2009.13888"
  },
  {
    "tags": [
      "Evaluation"
    ],
    "title": "What Question-Answering Can Learn from Trivia Nerds",
    "url": "https://aclanthology.org/2020.acl-main.662/"
  },
  {
    "tags": [
      "Critical",
      "Review"
    ],
    "title": "Language (technology) is power. A critical survey of \u201cbias\u201d in NLP.",
    "url": "https://aclanthology.org/2020.acl-main.485/"
  },
  {
    "tags": [
      "Legal",
      "Critical",
      "Ahead of Its Time"
    ],
    "title": "Foundation Models & Fair Use",
    "url": "https://arxiv.org/abs/2303.15715"
  },
  {
    "tags": [
      "Open Models",
      "Scaling",
      "Engineering",
      "Model",
      "Evaluation",
      "Internals"
    ],
    "title": "Pythia: ",
    "url": "https://arxiv.org/abs/2304.01373"
  },
  {
    "tags": [
      "Scaling",
      "Model"
    ],
    "title": "Training Compute-Optimal LLMs",
    "url": "https://arxiv.org/abs/2203.15556"
  },
  {
    "tags": [
      "Model",
      "Scaling",
      "Open Models",
      "Good Figure"
    ],
    "title": "LLaMA: Open and Efficient Foundation Language Models",
    "url": "https://arxiv.org/abs/2302.13971"
  },
  {
    "tags": [
      "Finetuning",
      "Ahead of Its Time"
    ],
    "title": "LoRA: Low-Rank Adaptation of Large Language Models",
    "url": "https://arxiv.org/abs/2106.09685"
  },
  {
    "tags": [
      "Finetuning"
    ],
    "title": "QLoRA: Efficient Finetuning of Quantized LLMs",
    "url": "https://arxiv.org/abs/2305.14314"
  },
  {
    "tags": [
      "Editing",
      "Internals",
      "Finetuning"
    ],
    "title": "Task Arithmetic in the Tangent Space: Improved Editing of Pre-Trained Models",
    "url": "https://arxiv.org/abs/2305.12827"
  },
  {
    "tags": [
      "Agency",
      "RL"
    ],
    "title": "Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory",
    "url": "https://raw.githubusercontent.com/OpenGVLab/GITM/main/GITM.pdf"
  },
  {
    "tags": [
      "Agency",
      "Amplification",
      "Chaining",
      "Reasoning"
    ],
    "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
    "url": "https://arxiv.org/abs/2305.14325"
  },
  {
    "tags": [
      "Evaluation",
      "Critical",
      "Scaling",
      "<30B",
      "Feedback",
      "Finetuning",
      "Dialogue",
      "Open Models"
    ],
    "title": "The False Promise of Imitating Proprietary LLMs",
    "url": "https://arxiv.org/abs/2305.15717"
  },
  {
    "tags": [
      "Evaluation",
      "Critical",
      "Ahead of Its Time"
    ],
    "title": "What Will it Take to Fix Benchmarking in Natural Language Understanding?",
    "url": "https://arxiv.org/abs/2104.02145"
  },
  {
    "tags": [
      "Alignment",
      "Amplification",
      "Feedback"
    ],
    "title": "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision",
    "url": "https://arxiv.org/abs/2305.03047"
  },
  {
    "tags": [
      "Prompting",
      "Critical",
      "Philosophy",
      "Simulation"
    ],
    "title": "Inducing anxiety in large language models increases exploration and bias",
    "url": "https://arxiv.org/abs/2304.11111v1"
  },
  {
    "tags": [
      "Model",
      "Evaluation",
      "Scaling"
    ],
    "title": "PaLM 2 Technical Report",
    "url": "https://ai.google/static/documents/palm2techreport.pdf"
  },
  {
    "tags": [
      "Evaluation",
      "Scaling",
      "Critical"
    ],
    "title": "Are Emergent Abilities of Large Language Models a Mirage?",
    "url": "https://arxiv.org/abs/2304.15004"
  },
  {
    "tags": [
      "Prompting",
      "Reasoning",
      "Internals",
      "Critical"
    ],
    "title": "Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting",
    "url": "https://arxiv.org/abs/2305.04388"
  },
  {
    "tags": [
      "Model",
      "Scaling"
    ],
    "title": "A Length-Extrapolatable Transformer",
    "url": "https://arxiv.org/abs/2212.10554"
  },
  {
    "tags": [
      "Model",
      "Feedback"
    ],
    "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback",
    "url": "https://arxiv.org/abs/2204.05862"
  },
  {
    "tags": [
      "Model",
      "Scaling",
      "<30B",
      "Evaluation",
      "Amplification"
    ],
    "title": "Tiny",
    "url": "https://arxiv.org/abs/2305.07759"
  },
  {
    "tags": [
      "Model"
    ],
    "title": "UL2: Unifying Language Learning Paradigms",
    "url": "https://arxiv.org/abs/2205.05131"
  },
  {
    "tags": [
      "Alignment"
    ],
    "title": "AI Safety via Debate",
    "url": "https://arxiv.org/abs/1805.00899"
  },
  {
    "tags": [
      "Evaluation",
      "Feedback",
      "Applications"
    ],
    "title": "Describing Differences between Text Distributions with Natural Language",
    "url": "https://arxiv.org/abs/2201.12323"
  },
  {
    "tags": [
      "Internals",
      "Evaluation"
    ],
    "title": "Explaining Patterns in Data with Language Models via Interpretable Autoprompting",
    "url": "https://arxiv.org/abs/2210.01848"
  },
  {
    "tags": [
      "Internals"
    ],
    "title": "A Toy Model of Universality: Reverse Engineering How Networks Learn Group Operations",
    "url": "https://arxiv.org/abs/2302.03025"
  },
  {
    "tags": [
      "Model"
    ],
    "title": "Learning to Execute",
    "url": "https://arxiv.org/abs/1410.4615"
  },
  {
    "tags": [
      "Evaluation",
      "Adversarial Inputs",
      "Security"
    ],
    "title": "Automatically Auditing Large Language Models via Discrete Optimization",
    "url": "https://arxiv.org/abs/2303.04381"
  },
  {
    "tags": [
      "Internals",
      "Reasoning",
      "Prompting",
      "Critical"
    ],
    "title": "Using cognitive psychology to understand GPT-3",
    "url": "https://www.pnas.org/doi/10.1073/pnas.2218523120"
  },
  {
    "tags": [
      "Prompting",
      "Decomposition",
      "Tool Use",
      "External Memory",
      "Good Figure"
    ],
    "title": "Decomposed Prompting: A Modular Approach for Solving Complex Tasks",
    "url": "https://arxiv.org/abs/2210.02406"
  },
  {
    "tags": [
      "Internals"
    ],
    "title": "Commonsense Knowledge Mining from Pretrained Models",
    "url": "https://arxiv.org/abs/1909.00505"
  },
  {
    "tags": [
      "Internals",
      "Grounding",
      "Philosophy",
      "Critical"
    ],
    "title": "Provable Limitations of Acquiring Meaning from Ungrounded Form: What Will Future Language Models Understand?",
    "url": "https://arxiv.org/abs/2104.10809"
  },
  {
    "tags": [
      "Engineering",
      "Applications",
      "Decomposition"
    ],
    "title": "Iterated Decomposition: Improving Science Q&A by Supervising Reasoning Processes",
    "url": "https://arxiv.org/abs/2301.01751"
  },
  {
    "tags": [
      "Ahead of Its Time"
    ],
    "title": "PROGRAMS WITH COMMON SENSE",
    "url": "http://jmc.stanford.edu/articles/mcc59/mcc59.pdf"
  },
  {
    "tags": [
      "Engineering",
      "Evaluation",
      "Critical"
    ],
    "title": "TextFlint: Unified Multilingual Robustness Evaluation Toolkit for Natural Language Processing",
    "url": "https://arxiv.org/abs/2103.11441"
  },
  {
    "tags": [
      "Philosophy",
      "Critical"
    ],
    "title": "The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",
    "url": "https://arxiv.org/abs/2002.06177"
  },
  {
    "tags": [
      "Reasoning",
      "Model"
    ],
    "title": "Explain Yourself! Leveraging Language Models for Commonsense Reasoning",
    "url": "https://arxiv.org/abs/1906.02361"
  },
  {
    "tags": [
      "External Memory",
      "Reasoning",
      "Finetuning",
      "Model"
    ],
    "title": "Human Parity on CommonsenseQA: Augmenting Self-Attention with External Attention",
    "url": "https://arxiv.org/abs/2112.03254"
  },
  {
    "tags": [
      "Few-Shot"
    ],
    "title": "Making Pre-trained Language Models Better Few-shot Learners",
    "url": "https://aclanthology.org/2021.acl-long.295/"
  },
  {
    "tags": [
      "Internals"
    ],
    "title": "Language Models (Mostly) Know What They Know",
    "url": "https://arxiv.org/abs/2207.05221"
  },
  {
    "tags": [
      "Tool Use",
      "Reasoning",
      "Decomposition",
      "Code"
    ],
    "title": "Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks",
    "url": "https://arxiv.org/abs/2211.12588"
  },
  {
    "tags": [
      "Reasoning",
      "Tool Use",
      "Feedback",
      "Robotics"
    ],
    "title": "Inner Monologue: Embodied Reasoning through Planning with Language Models",
    "url": "https://arxiv.org/abs/2207.05608"
  },
  {
    "tags": [
      "Multimodal",
      "<30B",
      "Few-Shot"
    ],
    "title": "Multimodal Chain-of-Thought Reasoning in Language Models",
    "url": "https://arxiv.org/abs/2302.00923"
  },
  {
    "tags": [
      "Finetuning",
      "<30B",
      "Few-Shot"
    ],
    "title": "How Many Data Points is a Prompt Worth?",
    "url": "https://arxiv.org/abs/2103.08493"
  },
  {
    "tags": [
      "Tool Use",
      "Model",
      "Grounding"
    ],
    "title": "Do as I can, not as I say: Grounding Language in Robotic Affordances (SayCan)",
    "url": "https://arxiv.org/abs/2204.01691"
  },
  {
    "tags": [
      "Tool Use",
      "Finetuning"
    ],
    "title": "Neural Execution Engines: Learning to Execute Subroutines",
    "url": "https://arxiv.org/abs/2006.08084"
  },
  {
    "tags": [
      "Prompting",
      "Finetuning"
    ],
    "title": "Cutting Down on Prompts and Parameters",
    "url": "https://arxiv.org/abs/2106.13353"
  },
  {
    "tags": [
      "Evaluation"
    ],
    "title": "Surface Form Competition: Why the Highest Probability Answer Isn\u2019t Always Right",
    "url": "https://arxiv.org/abs/2104.08315"
  },
  {
    "tags": [
      "Feedback",
      "Code",
      "Finetuning"
    ],
    "title": "Improving Code Generation by Training with Natural Language Feedback",
    "url": "https://arxiv.org/abs/2303.16749#"
  },
  {
    "tags": [
      "Reasoning",
      "Tool Use"
    ],
    "title": "Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents",
    "url": "https://arxiv.org/abs/2201.07207"
  },
  {
    "tags": [
      "Reasoning",
      "<30B",
      "Finetuning"
    ],
    "title": "Teaching Small Language Models to Reason",
    "url": "https://arxiv.org/abs/2212.08410"
  },
  {
    "tags": [
      "Ahead of Its Time",
      "Robotics"
    ],
    "title": "ALVINN: An Autonomous Land Vehicle in a Neural Network",
    "url": "https://proceedings.neurips.cc/paper/1988/file/812b4ba287f5ee0bc9d43bbf5bbe87fb-Paper.pdf"
  },
  {
    "tags": [
      "Model",
      "Reasoning",
      "Code"
    ],
    "title": "Reasoning like program executors",
    "url": "https://arxiv.org/abs/2201.11473"
  },
  {
    "tags": [
      "Prompting",
      "Decomposition"
    ],
    "title": "Reframing Instructional Prompts to GPTk's Language",
    "url": "https://arxiv.org/abs/2109.07830"
  },
  {
    "tags": [
      "Reasoning",
      "Critical"
    ],
    "title": "Human-like property induction is a challenge for large language models",
    "url": "https://escholarship.org/uc/item/3w84q1s1"
  },
  {
    "tags": [
      "Dataset",
      "Reasoning",
      "<30B"
    ],
    "title": "Are NLP Models really able to Solve Simple Math Word Problems?",
    "url": "https://arxiv.org/abs/2103.07191"
  },
  {
    "tags": [
      "Philosophy",
      "Critical"
    ],
    "title": "Why AI is Harder Than We Think",
    "url": "https://arxiv.org/abs/2104.12871"
  },
  {
    "tags": [
      "Review",
      "Philosophy",
      "Internals",
      "Scaling",
      "Alignment",
      "Evaluation"
    ],
    "title": "Eight Things to Know about Large Language Models",
    "url": "https://cims.nyu.edu/~sbowman/eightthings.pdf"
  },
  {
    "tags": [
      "Few-Shot",
      "Prompting",
      "Reasoning",
      "Critical"
    ],
    "title": "Investigating the Effect of Natural Language Explanations on Out-of-Distribution Generalization in Few-shot NLI",
    "url": "https://arxiv.org/abs/2110.06223"
  },
  {
    "tags": [
      "Internals",
      "Philosophy"
    ],
    "title": "Inductive Biases for Deep Learning of Higher-Level Cognition",
    "url": "https://arxiv.org/abs/2011.15091"
  },
  {
    "tags": [
      "Multimodal",
      "Tool Use",
      "Model",
      "Scaling"
    ],
    "title": "PaLM-E: An Embodied Multimodal Language Model",
    "url": "https://arxiv.org/abs/2303.03378"
  },
  {
    "tags": [
      "Scaling",
      "Engineering"
    ],
    "title": "GLaM: Efficient Scaling of Language Models with Mixture-of-Experts",
    "url": "https://arxiv.org/abs/2112.06905"
  },
  {
    "tags": [
      "Finetuning",
      "Reasoning"
    ],
    "title": "Unsupervised Commonsense Question Answering with Self-Talk",
    "url": "https://aclanthology.org/2020.emnlp-main.373/"
  },
  {
    "tags": [
      "Internals"
    ],
    "title": "How can we know what language models know?",
    "url": "https://arxiv.org/abs/1911.12543"
  },
  {
    "tags": [
      "Scaling"
    ],
    "title": "Emergent Abilities of Large Language Models",
    "url": "https://arxiv.org/abs/2206.07682"
  },
  {
    "tags": [],
    "title": "Language Models as Knowledge Bases?",
    "url": "https://arxiv.org/abs/1909.01066"
  },
  {
    "tags": [
      "Internals",
      "Critical"
    ],
    "title": "Schrodinger\u2019s Tree - On Syntax and Neural Language Models",
    "url": "https://arxiv.org/pdf/2110.08887.pdf"
  },
  {
    "tags": [
      "RL",
      "Agency"
    ],
    "title": "Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos",
    "url": "https://arxiv.org/abs/2206.11795"
  },
  {
    "tags": [
      "Few-Shot"
    ],
    "title": "True Few-Shot Learning with Language Models",
    "url": "https://arxiv.org/abs/2105.11447"
  },
  {
    "tags": [
      "Model",
      "Scaling",
      "<30B"
    ],
    "title": "RWKV",
    "url": "https://arxiv.org/abs/2305.13048"
  },
  {
    "tags": [
      "External Memory",
      "Model"
    ],
    "title": "Improving language models by retrieving from trillions of tokens (RETRO)",
    "url": "https://arxiv.org/abs/2112.04426"
  },
  {
    "tags": [
      "Finetuning",
      "Model"
    ],
    "title": "Learning to Generate Task-Specific Adapters from Task Description",
    "url": "https://arxiv.org/abs/2101.00420"
  },
  {
    "tags": [
      "Evaluation",
      "Dataset"
    ],
    "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods",
    "url": "https://aclanthology.org/2022.acl-long.229/"
  },
  {
    "tags": [
      "Tool Use",
      "Prompting"
    ],
    "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
    "url": "https://react-lm.github.io/"
  },
  {
    "tags": [
      "Evaluation",
      "Dataset",
      "Good Figure",
      "Scaling"
    ],
    "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models",
    "url": "https://arxiv.org/abs/2206.04615"
  },
  {
    "tags": [
      "Internals",
      "Reasoning",
      "Grounding",
      "<30B"
    ],
    "title": "Do Language Models Have Beliefs? Methods for Detecting, Updating, and Visualizing Model Beliefs",
    "url": "https://arxiv.org/abs/2111.13654"
  },
  {
    "tags": [
      "Amplification",
      "Reasoning",
      "Prompting"
    ],
    "title": "Automatic Chain of Thought Prompting in Large Language Models",
    "url": "https://arxiv.org/abs/2210.03493"
  },
  {
    "tags": [
      "Finetuning",
      "Prompting",
      "Few-Shot"
    ],
    "title": "Calibrate Before Use: Improving Few-Shot Performance of Language Models",
    "url": "https://arxiv.org/abs/2102.09690"
  },
  {
    "tags": [
      "Internals",
      "Critical"
    ],
    "title": "When classifying grammatical role, BERT doesn\u2019t care about word order... except when it matters",
    "url": "https://aclanthology.org/2022.acl-short.71/"
  },
  {
    "tags": [
      "Prompting",
      "Reasoning",
      "Few-Shot",
      "3.5 series"
    ],
    "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
    "url": "https://arxiv.org/abs/2201.11903"
  },
  {
    "tags": [
      "UX/HCI",
      "Philosophy",
      "Tool Use",
      "Model",
      "Good Figure",
      "<30B"
    ],
    "title": "Language Models are General-Purpose Interfaces",
    "url": "https://arxiv.org/abs/2206.06336"
  },
  {
    "tags": [
      "Few-Shot",
      "External Memory"
    ],
    "title": "What Makes Good In-Context Examples for GPT-3?",
    "url": "https://arxiv.org/abs/2101.06804"
  },
  {
    "tags": [
      "Internals"
    ],
    "title": "Quantifying Attention Flow in Transformers",
    "url": "https://arxiv.org/abs/2005.00928"
  },
  {
    "tags": [
      "Internals",
      "Critical",
      "<30B",
      "Grounding"
    ],
    "title": "Do Neural Language Representations Learn Physical Commonsense?",
    "url": "https://arxiv.org/abs/1908.02899"
  },
  {
    "tags": [
      "Critical"
    ],
    "title": "When a sentence does not introduce a discourse entity, Transformer-based models still sometimes refer to it",
    "url": "https://arxiv.org/abs/2205.03472"
  },
  {
    "tags": [
      "Model",
      "Evaluation",
      "Reasoning",
      "Multimodal",
      "Good Figure"
    ],
    "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
    "url": "https://arxiv.org/abs/2303.12712"
  },
  {
    "tags": [
      "<30B",
      "Internals",
      "Grounding"
    ],
    "title": "Can Language Models Encode Perceptual Structure Without Grounding? A Case Study in Color",
    "url": "https://arxiv.org/abs/2109.06129"
  },
  {
    "tags": [
      "Prompting",
      "Ahead of Its Time"
    ],
    "title": "Prompt Programming for Large Language Models",
    "url": "https://arxiv.org/abs/2102.07350"
  },
  {
    "tags": [
      "Prompting",
      "Reasoning",
      "3.5 series"
    ],
    "title": "Large Language Models are Zero-Shot Reasoners - Let\u2019s Think Step by Step",
    "url": "https://arxiv.org/abs/2205.11916"
  },
  {
    "tags": [
      "Amplification",
      "Ahead of Its Time"
    ],
    "title": "Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP",
    "url": "https://arxiv.org/abs/2103.00453"
  },
  {
    "tags": [
      "Prompting",
      "Applications",
      "Chaining",
      "UX/HCI"
    ],
    "title": "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts",
    "url": "https://dl.acm.org/doi/abs/10.1145/3491102.3517582"
  },
  {
    "tags": [
      "Vision",
      "Scaling",
      "Model",
      "Internals"
    ],
    "title": "Scaling Vision Transformers to 22 Billion Parameters",
    "url": "https://arxiv.org/abs/2302.05442"
  },
  {
    "tags": [
      "Dataset"
    ],
    "title": "Did Aristotle Use a Laptop? StrategyQA",
    "url": "https://arxiv.org/abs/2101.02235"
  },
  {
    "tags": [
      "Tool Use",
      "Reasoning"
    ],
    "title": "Tell me why! Explanations support learning relational and causal structure",
    "url": "https://arxiv.org/abs/2112.03753"
  },
  {
    "tags": [
      "Evaluation"
    ],
    "title": "HELM: Holistic Evaluation of Language Models",
    "url": "https://arxiv.org/abs/2211.09110"
  },
  {
    "tags": [
      "Reasoning",
      "Code"
    ],
    "title": "LLMs meet program synthesis",
    "url": "https://arxiv.org/abs/2112.02969"
  },
  {
    "tags": [
      "Prompting"
    ],
    "title": "Noisy Channel Language Model Prompting",
    "url": "https://arxiv.org/abs/2108.04106"
  },
  {
    "tags": [
      "Prompting",
      "Reasoning",
      "Ahead of Its Time"
    ],
    "title": "Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2",
    "url": "https://arxiv.org/abs/2103.13033"
  },
  {
    "tags": [
      "Reasoning",
      "Chaining",
      "<30B"
    ],
    "title": "Faithful Reasoning Using Large Language Models",
    "url": "https://arxiv.org/abs/2208.14271"
  },
  {
    "tags": [
      "Reasoning",
      "Critical"
    ],
    "title": "Language models show human-like content effects on reasoning",
    "url": "https://arxiv.org/abs/2207.07051"
  },
  {
    "tags": [
      "UX/HCI",
      "Engineering"
    ],
    "title": "On Human Intellect and Machine Failures: Troubleshooting Integrative Machine Learning Systems",
    "url": "https://arxiv.org/abs/1611.08309"
  },
  {
    "tags": [
      "Tool Use",
      "Prompting"
    ],
    "title": "MRKL Systems: A modular neuro-symbolic architecture that combines large language models, external knowledge sources, and discrete reasoning",
    "url": "https://arxiv.org/abs/2205.00445"
  },
  {
    "tags": [
      "Ahead of Its Time",
      "Model",
      "Applications",
      "Few-Shot"
    ],
    "title": "Experiments and Prospects of Example-Based Machine Translation",
    "url": "https://aclanthology.org/P91-1024.pdf"
  },
  {
    "tags": [
      "Internals",
      "Philosophy"
    ],
    "title": "Meaning without reference in large language models",
    "url": "https://arxiv.org/abs/2208.02957"
  },
  {
    "tags": [
      "Model",
      "Feedback",
      "Instruction"
    ],
    "title": "InstructGPT - Training language models to follow instructions with human feedback",
    "url": "https://arxiv.org/abs/2203.02155"
  },
  {
    "tags": [
      "Prompting",
      "Evaluation",
      "UX/HCI"
    ],
    "title": "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",
    "url": "https://arxiv.org/abs/2203.06566"
  },
  {
    "tags": [
      "Evaluation",
      "Critical",
      "Engineering"
    ],
    "title": "To Ship or Not to Ship: An Extensive Evaluation of Automatic Metrics for Machine Translation",
    "url": "https://arxiv.org/abs/2107.10821"
  },
  {
    "tags": [
      "Internals",
      "Few-Shot"
    ],
    "title": "Data Distributional Properties Drive Emergent In-Context Learning in Transformers",
    "url": "https://arxiv.org/abs/2205.05055"
  },
  {
    "tags": [
      "Internals",
      "Reasoning",
      "Philosophy",
      "<30B",
      "Critical",
      "Grounding"
    ],
    "title": "Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data",
    "url": "https://aclanthology.org/2020.acl-main.463/"
  },
  {
    "tags": [
      "Amplification",
      "Simulation",
      "Dialogue",
      "UX/HCI"
    ],
    "title": "Social Simulacra: Creating Populated Prototypes for Social Computing System",
    "url": "https://arxiv.org/abs/2208.04024"
  },
  {
    "tags": [
      "Evaluation",
      "Other"
    ],
    "title": "Hard negative examples are hard, but useful",
    "url": "https://arxiv.org/abs/2007.12749"
  },
  {
    "tags": [
      "Internals",
      "Critical",
      "Evaluation"
    ],
    "title": "Quantifying Memorization Across Neural Language Models",
    "url": "https://arxiv.org/abs/2202.07646"
  },
  {
    "tags": [
      "Few-Shot",
      "3.5 series"
    ],
    "title": "Larger language models do in-context learning differently",
    "url": "https://arxiv.org/abs/2303.03846"
  },
  {
    "tags": [
      "Reasoning",
      "Internals",
      "Probabilistic Programs"
    ],
    "title": "Towards Interpretable Natural Language Understanding with Explanations as Latent Variables",
    "url": "https://arxiv.org/abs/2011.05268"
  },
  {
    "tags": [
      "Applications",
      "Feedback"
    ],
    "title": "Recursively Summarizing Books with Human Feedback",
    "url": "https://arxiv.org/abs/2109.10862"
  },
  {
    "tags": [
      "Applications"
    ],
    "title": "A Recipe For Arbitrary Text Style Transfer with Large Language Models",
    "url": "https://arxiv.org/abs/2109.03910"
  },
  {
    "tags": [
      "Model",
      "Few-Shot"
    ],
    "title": "Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference - PET",
    "url": "https://arxiv.org/abs/2001.07676"
  },
  {
    "tags": [
      "Reasoning",
      "Adversarial Inputs"
    ],
    "title": "Can Rationalization Improve Robustness?",
    "url": "https://arxiv.org/abs/2204.11790"
  },
  {
    "tags": [
      "Few-Shot",
      "Critical"
    ],
    "title": "Fantastically Ordered Prompts and Where to Find Them",
    "url": "https://arxiv.org/abs/2104.08786"
  },
  {
    "tags": [
      "Instruction",
      "Dataset",
      "Model"
    ],
    "title": "Super-Natural Instructions: Generalization via Declarative Instructions on 1600+ NLP Tasks",
    "url": "https://arxiv.org/abs/2204.07705"
  },
  {
    "tags": [
      "Philosophy",
      "Internals",
      "Feedback",
      "RL"
    ],
    "title": "RL with KL penalties is better viewed as Bayesian inference",
    "url": "https://arxiv.org/abs/2205.11275"
  },
  {
    "tags": [
      "Prompting"
    ],
    "title": "Dissociating Language and Thought in LLMs",
    "url": "https://arxiv.org/abs/2301.06627"
  },
  {
    "tags": [
      "Prompting"
    ],
    "title": "Explanation of In-Context Learning as Implicit Bayesian Inference",
    "url": "https://arxiv.org/abs/2111.02080"
  },
  {
    "tags": [
      "Vision",
      "Scaling",
      "Model",
      "Good Figure"
    ],
    "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
    "url": "https://arxiv.org/abs/2010.11929"
  },
  {
    "tags": [
      "Prompting",
      "Finetuning"
    ],
    "title": "Towards a Unified View of Parameter-Efficient Transfer Learning",
    "url": "https://arxiv.org/abs/2110.04366"
  },
  {
    "tags": [
      "Prompting",
      "Feedback",
      "Amplification",
      "Instruction"
    ],
    "title": "Wisdom of Hindsight Makes Language Models Better Instruction Followers",
    "url": "https://arxiv.org/abs/2302.05206"
  },
  {
    "tags": [
      "Applications",
      "UX/HCI"
    ],
    "title": "Human-Centered Tools for Coping with Imperfect Algorithms during Medical Decision-Making",
    "url": "https://arxiv.org/abs/1902.02960"
  },
  {
    "tags": [
      "Prompting",
      "Reasoning"
    ],
    "title": "Rationale-Augmented Ensembles in Language Models",
    "url": "https://arxiv.org/abs/2207.00747"
  },
  {
    "tags": [
      "Evaluation",
      "Dataset",
      "Critical"
    ],
    "title": "TextFlint: Unified Multilingual Robustness Evaluation Toolkit for Natural Language Processing",
    "url": "https://arxiv.org/abs/2103.11441#"
  },
  {
    "tags": [
      "Reasoning",
      "Critical",
      "Few-Shot",
      "3.5 series"
    ],
    "title": "The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning",
    "url": "https://arxiv.org/abs/2205.03401"
  },
  {
    "tags": [
      "Code",
      "Few-Shot",
      "Prompting",
      "Tool Use",
      "External Memory"
    ],
    "title": "Evaluating the Text-to-SQL Capabilities of Large Language Models",
    "url": "https://arxiv.org/abs/2204.00498#"
  },
  {
    "tags": [
      "Few-Shot",
      "Prompting",
      "Instruction",
      "Reasoning"
    ],
    "title": "In-Context Instruction Learning",
    "url": "https://arxiv.org/abs/2302.14691"
  },
  {
    "tags": [
      "Evaluation"
    ],
    "title": "Faithfulness and Factuality in Abstractive Summarization",
    "url": "https://aclanthology.org/2020.acl-main.173.pdf"
  },
  {
    "tags": [
      "Evaluation"
    ],
    "title": "On the state of the art of evaluation in neural LMs",
    "url": "https://arxiv.org/abs/1707.05589"
  },
  {
    "tags": [
      "Prompting",
      "Amplification",
      "Reasoning",
      "Tool Use"
    ],
    "title": "Reflexion: an autonomous agent with dynamic memory and self-reflection",
    "url": "https://arxiv.org/abs/2303.11366"
  },
  {
    "tags": [
      "UX/HCI",
      "Robotics",
      "Critical"
    ],
    "title": "Challenges in Shared-Environment Human-Robot Collaboration",
    "url": "http://bradhayes.info/papers/hayes_challenges_HRI_collab_2013.pdf"
  },
  {
    "tags": [
      "Critical",
      "Internals"
    ],
    "title": "Word Order Does Matter and Shuffled Language Models Know It",
    "url": "https://aclanthology.org/2022.acl-long.476/"
  },
  {
    "tags": [
      "UX/HCI"
    ],
    "title": "Re-examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design",
    "url": "https://dl.acm.org/doi/10.1145/3313831.3376301"
  },
  {
    "tags": [
      "Review",
      "Philosophy"
    ],
    "title": "On the Opportunities and Risks of Foundation Models \u2014 Intro",
    "url": "https://arxiv.org/abs/2108.07258"
  },
  {
    "tags": [
      "Ahead of Its Time",
      "External Memory"
    ],
    "title": "How Context Affects Language Models' Factual Predictions",
    "url": "https://arxiv.org/abs/2005.04611"
  },
  {
    "tags": [
      "Reasoning",
      "<30B",
      "Ahead of Its Time",
      "Prompting"
    ],
    "title": "When can models learn from explanations?",
    "url": "https://arxiv.org/abs/2102.02201"
  },
  {
    "tags": [
      "Prompting",
      "Review"
    ],
    "title": "Pre-Train Prompt Predict: Review of Prompting Strategies",
    "url": "https://dl.acm.org/doi/pdf/10.1145/3560815"
  },
  {
    "tags": [
      "Tool Use",
      "Finetuning"
    ],
    "title": "Toolformer: Language Models Can Teach Themselves To Use Tools",
    "url": "https://arxiv.org/abs/2302.04761"
  },
  {
    "tags": [
      "Reasoning",
      "Philosophy"
    ],
    "title": "Resource-rational analysis: Understanding human cognition as the optimal use of limited computational resources",
    "url": "https://cocosci.princeton.edu/papers/lieder_resource.pdf"
  },
  {
    "tags": [
      "Review",
      "Tool Use",
      "External Memory",
      "Reasoning",
      "Decomposition"
    ],
    "title": "Augmented Language Models: a Survey",
    "url": "https://arxiv.org/abs/2302.07842"
  },
  {
    "tags": [
      "Model",
      "Scaling",
      "Evaluation",
      "Code",
      "Reasoning",
      "Security"
    ],
    "title": "GPT-4 Technical Report",
    "url": "https://cdn.openai.com/papers/gpt-4.pdf"
  },
  {
    "tags": [
      "Few-Shot",
      "Reasoning",
      "Model",
      "Code"
    ],
    "title": "Language Models of Code are Few-Shot Commonsense Learners",
    "url": "https://arxiv.org/abs/2210.07128"
  },
  {
    "tags": [
      "Reasoning",
      "Feedback",
      "Few-Shot",
      "Prompting",
      "Code"
    ],
    "title": "Program Synthesis with Large Language Models",
    "url": "https://arxiv.org/abs/2108.07732"
  },
  {
    "tags": [
      "Model",
      "Finetuning",
      "Instruction"
    ],
    "title": "Fine-tuned Language Models are Zero-Shot Learners - FLAN",
    "url": "https://arxiv.org/abs/2109.01652"
  },
  {
    "tags": [
      "Prompting",
      "Reasoning",
      "Decomposition",
      "3.5 series"
    ],
    "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models",
    "url": "https://arxiv.org/abs/2205.10625"
  },
  {
    "tags": [
      "Model",
      "Scaling",
      "Dataset",
      "Ahead of Its Time"
    ],
    "title": "ByT5: Towards a token-free future with pre-trained byte-to-byte model",
    "url": "https://arxiv.org/abs/2105.13626"
  },
  {
    "tags": [
      "Dataset"
    ],
    "title": "The Pile",
    "url": "https://arxiv.org/abs/2101.00027"
  },
  {
    "tags": [
      "Philosophy",
      "Critical",
      "Applications"
    ],
    "title": "Ethical and social risks of harm from Language Models",
    "url": "https://arxiv.org/abs/2112.04359"
  },
  {
    "tags": [
      "Agency",
      "Tool Use",
      "Reasoning",
      "Decomposition"
    ],
    "title": "Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents",
    "url": "https://arxiv.org/abs/2302.01560"
  },
  {
    "tags": [
      "Few-Shot",
      "Reasoning",
      "<30B"
    ],
    "title": "Impact of Pretraining Term Frequencies on Few-Shot Reasoning",
    "url": "https://arxiv.org/abs/2202.07206"
  },
  {
    "tags": [
      "Prompting",
      "Reasoning",
      "Few-Shot"
    ],
    "title": "Complexity-Based Prompting for Multi-Step Reasoning",
    "url": "https://arxiv.org/abs/2210.00720"
  },
  {
    "tags": [
      "Applications",
      "UX/HCI"
    ],
    "title": "Nine Potential Pitfalls when Designing Human-AI Co-Creative Systems",
    "url": "https://arxiv.org/abs/2104.00358"
  },
  {
    "tags": [
      "Internals"
    ],
    "title": "Locating and editing factual associations in GPT",
    "url": "https://arxiv.org/abs/2202.05262"
  },
  {
    "tags": [
      "Feedback"
    ],
    "title": "f-Divergences for explaining LM alignments to preferences",
    "url": "https://arxiv.org/abs/2302.08215"
  },
  {
    "tags": [
      "Applications",
      "UX/HCI"
    ],
    "title": "Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models",
    "url": "https://dl.acm.org/doi/10.1145/3313831.3376739"
  },
  {
    "tags": [
      "Simulation",
      "Internals",
      "Philosophy",
      "Amplification",
      "<30B"
    ],
    "title": "Language Models as Agent Models",
    "url": "https://arxiv.org/abs/2212.01681"
  },
  {
    "tags": [
      "Review",
      "Security",
      "Philosophy",
      "Critical"
    ],
    "title": "Gradient of Generative AI Release",
    "url": "https://arxiv.org/abs/2302.04844"
  },
  {
    "tags": [
      "Ahead of Its Time",
      "External Memory",
      "Applications"
    ],
    "title": "Teaching language models to support answers with verified quotes",
    "url": "https://arxiv.org/abs/2203.11147"
  },
  {
    "tags": [
      "Reasoning"
    ],
    "title": "Explainable Multi-hop Reasoning through Internal Monologue",
    "url": "https://aclanthology.org/2021.naacl-main.97.pdf"
  },
  {
    "tags": [
      "Prompting",
      "Model",
      "Engineering",
      "<30B"
    ],
    "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization - T0",
    "url": "https://arxiv.org/abs/2110.08207"
  },
  {
    "tags": [
      "Prompting",
      "Reasoning",
      "Probabilistic Programs",
      "Few-Shot",
      "3.5 series"
    ],
    "title": "Self-Consistency Improves CoT Reasoning",
    "url": "https://arxiv.org/abs/2203.11171"
  },
  {
    "tags": [
      "Scaling",
      "Model"
    ],
    "title": "Megatron-LM",
    "url": "https://arxiv.org/abs/1909.08053"
  },
  {
    "tags": [
      "Critical",
      "Internals",
      "Ahead of Its Time"
    ],
    "title": "Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models",
    "url": "https://arxiv.org/abs/2205.10770"
  },
  {
    "tags": [
      "Reasoning",
      "Critical",
      "Instruction",
      "Prompting",
      "Negation",
      "Good Figure"
    ],
    "title": "Can Large Language Models Truly Understand Prompts? A Case Study with Negated Prompts",
    "url": "https://arxiv.org/abs/2209.12711"
  },
  {
    "tags": [
      "Evaluation",
      "Reasoning",
      "3.5 series",
      "Scaling",
      "Few-Shot",
      "Prompting"
    ],
    "title": "Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them",
    "url": "https://arxiv.org/abs/2210.09261"
  },
  {
    "tags": [
      "Evaluation",
      "Dataset",
      "Code",
      "Critical"
    ],
    "title": "The Adverse Effects of Code Duplication in Machine Learning Models of Code",
    "url": "https://arxiv.org/abs/1812.06469"
  },
  {
    "tags": [
      "Prompting",
      "Internals",
      "Reasoning",
      "Few-Shot",
      "3.5 series"
    ],
    "title": "Text and Patterns: For CoT, Two to Tango",
    "url": "https://arxiv.org/abs/2209.07686"
  },
  {
    "tags": [
      "Scaling"
    ],
    "title": "An Empirical Model of Large-Batch Training",
    "url": "https://arxiv.org/abs/1812.06162"
  },
  {
    "tags": [
      "Decomposition",
      "Reasoning",
      "Prompting",
      "Good Figure"
    ],
    "title": "Measuring and Narrowing the Compositionality Gap in Language Models - SelfAsk",
    "url": "https://arxiv.org/abs/2210.03350"
  },
  {
    "tags": [
      "Reasoning",
      "Critical",
      "Few-Shot",
      "Prompting"
    ],
    "title": "Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters",
    "url": "https://arxiv.org/abs/2212.10001"
  },
  {
    "tags": [
      "Internals",
      "<30B",
      "Ahead of Its Time"
    ],
    "title": "Commonsense Knowledge Mining from Pretrained Models",
    "url": "https://arxiv.org/abs/1909.00505"
  },
  {
    "tags": [
      "Critical",
      "Few-Shot"
    ],
    "title": "Rethinking the role of demonstrations",
    "url": "https://arxiv.org/abs/2202.12837"
  },
  {
    "tags": [
      "Amplification",
      "Ahead of Its Time",
      "<30B",
      "Dataset",
      "Instruction"
    ],
    "title": "Generating Datasets with Pretrained Language Models",
    "url": "https://arxiv.org/abs/2104.07540"
  },
  {
    "tags": [
      "Instruction",
      "Dataset"
    ],
    "title": "Cross-Task Generalization via Natural Language Crowdsourcing Instructions",
    "url": "https://arxiv.org/abs/2104.08773"
  },
  {
    "tags": [
      "Internals",
      "Grounding"
    ],
    "title": "Implicit Representations of Meaning in Neural Language Models",
    "url": "https://arxiv.org/abs/2106.00737"
  },
  {
    "tags": [
      "Reasoning",
      "Prompting",
      "Decomposition"
    ],
    "title": "Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks",
    "url": "https://arxiv.org/abs/2204.02892"
  },
  {
    "tags": [
      "Instruction",
      "Few-Shot",
      "Model"
    ],
    "title": "OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization",
    "url": "https://arxiv.org/abs/2212.12017"
  },
  {
    "tags": [
      "Reasoning",
      "Model",
      "<30B"
    ],
    "title": "Transformers as Soft Reasoners over Language",
    "url": "https://arxiv.org/abs/2002.05867"
  },
  {
    "tags": [
      "Few-Shot",
      "Model"
    ],
    "title": "MetaICL: Learning to Learn In Context",
    "url": "https://arxiv.org/abs/2110.15943"
  },
  {
    "tags": [
      "Tool Use",
      "Amplification",
      "<30B"
    ],
    "title": "TALM: Tool Augmented Language Models",
    "url": "https://arxiv.org/abs/2205.12255"
  },
  {
    "tags": [
      "Tool Use",
      "Finetuning",
      "Ahead of Its Time",
      "External Memory",
      "Chaining"
    ],
    "title": "WebGPT: ",
    "url": "https://arxiv.org/abs/2112.09332"
  },
  {
    "tags": [
      "Code",
      "Evaluation",
      "Model",
      "<30B"
    ],
    "title": "A Systematic Evaluation of Large Language Models of Code",
    "url": "https://arxiv.org/abs/2202.13169"
  },
  {
    "tags": [
      "Philosophy"
    ],
    "title": "Communicative Efficiency, Uniform Information Density, and the Rational\nSpeech Act theory",
    "url": "https://cogsci.mindmodeling.org/2018/papers/0146/0146.pdf"
  },
  {
    "tags": [
      "Philosophy",
      "Critical"
    ],
    "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? \ud83e\udd9c",
    "url": "https://dl.acm.org/doi/10.1145/3442188.3445922"
  },
  {
    "tags": [
      "Model"
    ],
    "title": "What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?",
    "url": "https://arxiv.org/abs/2204.05832"
  },
  {
    "tags": [
      "Prompting",
      "Instruction",
      "Decomposition"
    ],
    "title": "SeqZero: Few-shot Compositional Semantic Parsing with Sequential Prompts and Zero-shot Models",
    "url": "https://arxiv.org/abs/2205.07381"
  },
  {
    "tags": [
      "Evaluation",
      "Probabilistic Programs",
      "Good Figure"
    ],
    "title": "The Curious Case of Neural Text Degeneration",
    "url": "https://arxiv.org/abs/1904.09751"
  },
  {
    "tags": [
      "Prompting",
      "Reasoning"
    ],
    "title": "Think about it! Improving Defeasible Reasoning",
    "url": "https://arxiv.org/abs/2110.12349"
  },
  {
    "tags": [
      "Critical",
      "Review",
      "UX/HCI"
    ],
    "title": "Automation bias: a systematic review of frequency, effect mediators, and mitigators",
    "url": "https://pubmed.ncbi.nlm.nih.gov/21685142/"
  },
  {
    "tags": [
      "Amplification",
      "Code",
      "Tool Use"
    ],
    "title": "Language Models Can Teach Themselves to Program Better",
    "url": "https://arxiv.org/abs/2207.14502"
  },
  {
    "tags": [
      "Scaling",
      "Good Figure"
    ],
    "title": "Scaling Laws for Neural Language Models",
    "url": "https://arxiv.org/abs/2001.08361"
  },
  {
    "tags": [
      "Evaluation",
      "Dataset",
      "Critical",
      "<30B"
    ],
    "title": "Deduplicating Training Data Makes Language Models Better",
    "url": "https://arxiv.org/abs/2107.06499"
  },
  {
    "tags": [
      "Multimodal",
      "Scaling",
      "Prompting",
      "Model",
      "Vision"
    ],
    "title": "LiT: Zero-Shot Transfer with Locked-image text Tuning",
    "url": "https://arxiv.org/abs/2111.07991"
  },
  {
    "tags": [
      "Instruction",
      "<30B",
      "Ahead of Its Time"
    ],
    "title": "The Turking Test: Can Language Models Understand Instructions?",
    "url": "https://arxiv.org/abs/2010.11982"
  },
  {
    "tags": [
      "Model",
      "Engineering",
      "Scaling"
    ],
    "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher",
    "url": "https://arxiv.org/abs/2112.11446"
  },
  {
    "tags": [
      "Reasoning",
      "Finetuning"
    ],
    "title": "Show Your Work: Scratchpads for  Intermediate Computation with LMs",
    "url": "https://arxiv.org/abs/2112.00114"
  },
  {
    "tags": [
      "Critical",
      "Few-Shot",
      "<30B"
    ],
    "title": "Sorting through the noise: Testing robustness of information processing in pre-trained language models",
    "url": "https://arxiv.org/abs/2109.12393"
  },
  {
    "tags": [
      "Finetuning",
      "Reasoning",
      "Tool Use"
    ],
    "title": "Refining Language Models with Compositional Explanations",
    "url": "https://arxiv.org/abs/2103.10415"
  },
  {
    "tags": [
      "Few-Shot",
      "Internals"
    ],
    "title": "Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers",
    "url": "https://arxiv.org/abs/2212.10559"
  },
  {
    "tags": [
      "Internals"
    ],
    "title": "Measuring Attribution in Natural Language Generation Models",
    "url": "https://arxiv.org/abs/2112.12870"
  },
  {
    "tags": [
      "Applications",
      "UX/HCI",
      "Engineering"
    ],
    "title": "Guidelines for Human-AI Interaction",
    "url": "https://www.microsoft.com/en-us/research/uploads/prod/2019/01/Guidelines-for-Human-AI-Interaction-camera-ready.pdf"
  },
  {
    "tags": [
      "Model",
      "Scaling",
      "Multimodal"
    ],
    "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs",
    "url": "https://arxiv.org/abs/2107.14795"
  },
  {
    "tags": [
      "Reasoning",
      "Few-Shot"
    ],
    "title": "Can language models learn from explanations in context?",
    "url": "https://arxiv.org/abs/2204.02329"
  },
  {
    "tags": [
      "Amplification",
      "Feedback",
      "Finetuning"
    ],
    "title": "Training Language Models with Language Feedback at Scale",
    "url": "https://arxiv.org/abs/2303.16755"
  },
  {
    "tags": [
      "Finetuning",
      "Prompting"
    ],
    "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
    "url": "https://arxiv.org/abs/2101.00190"
  },
  {
    "tags": [
      "Prompting",
      "Tool Use",
      "Few-Shot",
      "Decomposition",
      "Chaining",
      "Reasoning",
      "External Memory"
    ],
    "title": "Language Models can Solve Computer Tasks",
    "url": "https://arxiv.org/abs/2303.17491"
  },
  {
    "tags": [
      "Feedback",
      "Amplification"
    ],
    "title": "The Capacity for Moral Self-Correction in Large Language Models",
    "url": "https://arxiv.org/abs/2302.07459"
  },
  {
    "tags": [
      "Critical",
      "Reasoning",
      "<30B",
      "Negation"
    ],
    "title": "Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly",
    "url": "https://aclanthology.org/2020.acl-main.698/"
  },
  {
    "tags": [
      "Prompting",
      "Finetuning",
      "<30B"
    ],
    "title": "The Power of Scale for Parameter-Efficient Prompt Tuning",
    "url": "https://arxiv.org/abs/2104.08691"
  },
  {
    "tags": [
      "Instruction",
      "3.5 series"
    ],
    "title": "Instruction Induction",
    "url": "https://arxiv.org/abs/2205.10782"
  },
  {
    "tags": [
      "Few-Shot",
      "Scaling"
    ],
    "title": "Ground-Truth Labels Matter",
    "url": "https://arxiv.org/abs/2205.12685"
  },
  {
    "tags": [
      "Multimodal",
      "Prompting"
    ],
    "title": "A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based Learning for Vision-Language Models",
    "url": "https://arxiv.org/abs/2110.08484"
  },
  {
    "tags": [
      "Prompting",
      "Amplification",
      "3.5 series"
    ],
    "title": "Large Language Models are Human-Level Prompt Engineers",
    "url": "https://sites.google.com/view/automatic-prompt-engineer"
  },
  {
    "tags": [
      "Internals",
      "Critical"
    ],
    "title": "What Context Features Can Transformer Language Models Use?",
    "url": "https://arxiv.org/abs/2106.08367"
  },
  {
    "tags": [
      "Security",
      "Finetuning"
    ],
    "title": "Self-Destructing Models: Increasing the Costs of Harmful Dual Uses in Foundation Models",
    "url": "https://arxiv.org/abs/2211.14946"
  },
  {
    "tags": [
      "Philosophy",
      "Critical"
    ],
    "title": "Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models",
    "url": "https://arxiv.org/abs/2102.02503"
  },
  {
    "tags": [
      "Scaling",
      "Dataset"
    ],
    "title": "Will we run out of data? ",
    "url": "https://arxiv.org/abs/2211.04325#"
  },
  {
    "tags": [
      "3.5 series",
      "Evaluation",
      "Feedback"
    ],
    "title": "A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models",
    "url": "https://arxiv.org/abs/2303.10420"
  },
  {
    "tags": [
      "Applications",
      "UX/HCI",
      "Ahead of Its Time"
    ],
    "title": "Mental Models in Human-Computer Interaction",
    "url": "https://ntrs.nasa.gov/api/citations/19890068859/downloads/19890068859.pdf"
  },
  {
    "tags": [
      "Applications",
      "Finetuning"
    ],
    "title": "Generate Natural Language Explanations for Recommendation",
    "url": "https://arxiv.org/abs/2101.03392"
  },
  {
    "tags": [
      "Scaling",
      "Internals"
    ],
    "title": "Predictability and Surprise in Large Generative Models",
    "url": "https://arxiv.org/abs/2202.07785"
  },
  {
    "tags": [
      "Evaluation",
      "Ahead of Its Time",
      "Good Figure"
    ],
    "title": "All That's 'Human' Is Not Gold: Evaluating Human Evaluation of Generated Text",
    "url": "https://arxiv.org/abs/2107.00061"
  },
  {
    "tags": [
      "Evaluation",
      "Critical",
      "Amplification",
      "<30B"
    ],
    "title": "Tomayto, Tomahto. Beyond Token-level Answer Equivalence for Question Answering Evaluation",
    "url": "https://arxiv.org/abs/2202.07654"
  },
  {
    "tags": [
      "Few-Shot",
      "Critical"
    ],
    "title": "Do Prompt-Based Models Really Understand The Meaning Of Their Prompts?",
    "url": "https://aclanthology.org/2022.naacl-main.167/"
  },
  {
    "tags": [
      "Internals",
      "Reasoning"
    ],
    "title": "Looped Transformers as Programmable Computers",
    "url": "https://arxiv.org/abs/2301.13196"
  },
  {
    "tags": [
      "Review",
      "Philosophy"
    ],
    "title": "What Do NLP Researchers Believe? Results of the NLP Community Metasurvey",
    "url": "https://arxiv.org/abs/2208.12852"
  },
  {
    "tags": [
      "Model",
      "Feedback"
    ],
    "title": "BlenderBot 3: a deployed conversational agent that continually learns to responsibly engage",
    "url": "https://arxiv.org/abs/2208.03188"
  },
  {
    "tags": [
      "Tool Use",
      "<30B",
      "Ahead of Its Time"
    ],
    "title": "Giving BERT a calculator",
    "url": "https://arxiv.org/abs/1909.00109"
  },
  {
    "tags": [
      "Robotics",
      "Tool Use"
    ],
    "title": "Interactive Language: Talking to Robots in Real Time",
    "url": "https://arxiv.org/abs/2210.06407"
  },
  {
    "tags": [
      "Model"
    ],
    "title": "CTRL: Conditional Transformer Language Model for Controllable Generation",
    "url": "https://arxiv.org/abs/1909.05858"
  },
  {
    "tags": [
      "Internals"
    ],
    "title": "Attention is Not Explanation",
    "url": "https://aclanthology.org/N19-1357/"
  },
  {
    "tags": [
      "Scaling"
    ],
    "title": "FlashAttention",
    "url": "https://arxiv.org/abs/2205.14135"
  },
  {
    "tags": [
      "Prompting",
      "Finetuning",
      "External Memory",
      "Few-Shot"
    ],
    "title": "Learning To Retrieve Prompts for In-Context Learning",
    "url": "https://arxiv.org/abs/2112.08633"
  },
  {
    "tags": [
      "Prompting",
      "Amplification"
    ],
    "title": "STaR: Self-Taught Reasoner. Bootstrapping Reasoning with Reasoning.",
    "url": "https://arxiv.org/abs/2203.14465"
  },
  {
    "tags": [
      "Reasoning",
      "Philosophy"
    ],
    "title": "Bounded Conditioning: Flexible Inference for Decisions under Scarce Resources",
    "url": "https://arxiv.org/abs/1304.1512"
  },
  {
    "tags": [
      "Evaluation"
    ],
    "title": "Reframing Human-AI Collaboration for Generating Free-Text Explanations",
    "url": "https://arxiv.org/abs/2112.08674"
  },
  {
    "tags": [
      "Ahead of Its Time",
      "Applications",
      "Critical"
    ],
    "title": "ELIZA\u2014a computer program for the study of natural language communication between man and machine",
    "url": "https://dl.acm.org/doi/10.1145/365153.365168"
  },
  {
    "tags": [
      "Model",
      "Multimodal"
    ],
    "title": "Towards General Purpose Vision Systems",
    "url": "https://arxiv.org/abs/2104.00743"
  },
  {
    "tags": [
      "Scaling"
    ],
    "title": "Inverse scaling can become U-shaped",
    "url": "https://arxiv.org/abs/2211.02011"
  },
  {
    "tags": [
      "Prompting",
      "Reasoning",
      "Few-Shot"
    ],
    "title": "Few-Shot Self-Rationalization with Natural Language Prompts",
    "url": "https://arxiv.org/abs/2111.08284"
  },
  {
    "tags": [
      "Evaluation",
      "Amplification",
      "Feedback"
    ],
    "title": "GPTEval: NLG Evaluation using GPT-4 with Better Human Alignment",
    "url": "https://arxiv.org/abs/2303.16634"
  },
  {
    "tags": [
      "Evaluation",
      "Model"
    ],
    "title": "Towards a Unified Multi-Dimensional Evaluator for Text Generation",
    "url": "https://arxiv.org/abs/2210.07197"
  },
  {
    "tags": [
      "Model",
      "Scaling",
      "Good Figure"
    ],
    "title": "PaLM: Pathways Language Model",
    "url": "https://arxiv.org/abs/2204.02311"
  },
  {
    "tags": [
      "Instruction",
      "Amplification",
      "Finetuning",
      "Dataset"
    ],
    "title": "Unnatural Instructions",
    "url": "https://arxiv.org/abs/2212.09689"
  },
  {
    "tags": [
      "Code",
      "Dialogue"
    ],
    "title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis",
    "url": "https://arxiv.org/abs/2203.13474"
  },
  {
    "tags": [
      "Prompting",
      "Engineering",
      "UX/HCI"
    ],
    "title": "PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts",
    "url": "https://arxiv.org/abs/2202.01279"
  },
  {
    "tags": [
      "Model",
      "Multimodal",
      "Ahead of Its Time"
    ],
    "title": "Flamingo: a Visual Language Model for Few-Shot Learning",
    "url": "https://arxiv.org/abs/2204.14198"
  },
  {
    "tags": [
      "Internals",
      "Few-Shot"
    ],
    "title": "Transformers generalize differently from information stored in context vs in weights",
    "url": "https://arxiv.org/abs/2210.05675"
  },
  {
    "tags": [
      "Model",
      "Ahead of Its Time"
    ],
    "title": "Jump to Conclusions: Short-Cutting Transformers With Linear Transformations",
    "url": "https://arxiv.org/abs/2303.09435"
  },
  {
    "tags": [
      "Prompting",
      "Amplification",
      "<30B",
      "Ahead of Its Time"
    ],
    "title": "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts",
    "url": "https://arxiv.org/abs/2010.15980"
  },
  {
    "tags": [
      "Dataset",
      "Evaluation",
      "Critical",
      "Reasoning",
      "<30B"
    ],
    "title": "Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference - HANS",
    "url": "https://aclanthology.org/P19-1334/"
  },
  {
    "tags": [
      "Philosophy",
      "Internals",
      "Ahead of Its Time"
    ],
    "title": "Do Animals Have Beliefs?",
    "url": "https://dl.tufts.edu/concern/pdfs/rj430g708"
  },
  {
    "tags": [
      "Philosophy"
    ],
    "title": "Towards a clarification of probability,\npossibility and plausibility: how semantics\ncould help futures practice to improve",
    "url": "https://cspo.org/wp-content/uploads/2014/11/read_van-der-Helm-Towards-a-Clarification-of-Probability.pdf"
  },
  {
    "tags": [
      "Reasoning",
      "<30B",
      "Finetuning"
    ],
    "title": "Large Language Models Are Reasoning Teachers",
    "url": "https://arxiv.org/abs/2212.10071"
  },
  {
    "tags": [
      "Internals",
      "External Memory"
    ],
    "title": "Memory Augmented Large Language Models are Computationally Universal",
    "url": "https://arxiv.org/abs/2301.04589"
  },
  {
    "tags": [
      "Tool Use",
      "External Memory",
      "Prompting",
      "Chaining"
    ],
    "title": "Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions",
    "url": "https://arxiv.org/abs/2212.10509"
  },
  {
    "tags": [
      "Model",
      "Multimodal"
    ],
    "title": "CLIP",
    "url": "https://arxiv.org/abs/2103.00020"
  },
  {
    "tags": [
      "Philosophy",
      "Other",
      "Critical"
    ],
    "title": "The generalizability crisis",
    "url": "https://psyarxiv.com/jqw35/"
  },
  {
    "tags": [
      "Scaling",
      "RL"
    ],
    "title": "Scaling Laws for Reward Model Overoptimization",
    "url": "https://arxiv.org/abs/2210.10760"
  },
  {
    "tags": [
      "Internals",
      "Finetuning"
    ],
    "title": "Pretrained Transformers as Universal Computation Engines",
    "url": "https://arxiv.org/abs/2103.05247"
  },
  {
    "tags": [
      "Evaluation",
      "Model",
      "Code"
    ],
    "title": "Evaluating Large Language Models Trained on Code",
    "url": "https://arxiv.org/abs/2107.03374"
  },
  {
    "tags": [
      "Model",
      "Dialogue"
    ],
    "title": "LaMDA: Language Models for Dialog Applications",
    "url": "https://arxiv.org/abs/2201.08239"
  },
  {
    "tags": [
      "Internals",
      "Reasoning",
      "Model",
      "<30B"
    ],
    "title": "Understanding by Understanding Not: Modeling Negation in Language Models",
    "url": "https://arxiv.org/abs/2105.03519"
  },
  {
    "tags": [
      "Review",
      "Probabilistic Programs"
    ],
    "title": "Language Model Cascades",
    "url": "https://arxiv.org/abs/2207.10342"
  },
  {
    "tags": [
      "Prompting",
      "Few-Shot"
    ],
    "title": "It\u2019s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners",
    "url": "https://aclanthology.org/2021.naacl-main.185/"
  },
  {
    "tags": [
      "Model"
    ],
    "title": "Cicero, the Diplomacy strategy bot",
    "url": "https://www.science.org/doi/10.1126/science.ade9097"
  }
]
