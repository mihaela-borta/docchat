sound engines are available [19] (see more in section 2.2).

This paper explores the potential of developing a realistic audio-visual environment for virtual reality, with the purpose of assessing participants' selective attention with a high degree of ecological validity. This includes implementing a realistic 3D scene and auralization of recorded audio.

## 2 Related Research

### Non-individualized HRTFs for hearing impaired

As mentioned in Section 1, it is crucial that the prototype is capable of rendering sound using an HRTF. However, creating an individualized HRTF for each listener can be limiting [12]. In a study by Brungard et al. (2017) [20], normal-hearing and hearing-impaired listeners were asked to localize noise using non-individualized HRTF and free-field speakers. The study found that hearing-impaired listeners were slightly more sensitive to individual differences in HRTFs. Nevertheless, the study concluded that the correlation between free-field and non-individualized results was close enough to suggest that a non-individualized HRTF may be feasible [20]. Other studies also consider non-individualized HRTFs to be viable due to the limitations and inconveniences of recording personalized Head-Related Impulse Responses (HRIRs) [12, 13, 20]. Based on the limitations of personalized HRTFs, the prototype presented in this paper will use a generic HRTF.

### Sound engines for auralization in VR

The implementation of realistic sound in VR experiences often requires the use of third-party sound engines. One option is Steam Audio, which enables the physical modeling of rooms using geometrical acoustics in an easy-to-use manner. Steam Audio can be considered an intermediate solution for game audio design and physically based modeling [19], and has been found to deliver fairly accurate results [21]. Other studies, such as [22], have successfully used Steam Audio to render realistic acoustics. Another option is the middleware Wwise, which offers different plugins for auralization. In a study by Firat et al. [19], the two sound engines were compared, and Steam Audio was found to be closer to real-world results for air absorption. Other more complex options also focus more on architectural acoustics; however, these cannot perform game audio tasks [19], which are needed for VR development. While it is difficult to conclude which sound engine is the better choice, Steam Audio appears to be a good option for easy-to-use and ecologically valid auralization, and will be used for rendering sound in the prototype.

### Testing selective attention in VR

Similar research has been conducted on testing selective attention in VR. For instance, Breuer et al. (2022) [23] present a VR classroom environment for assessing selective attention in children, where both distracting and target stimuli are played simultaneously (see Figure 1). The children's main objective is to categorize the target auditory stimuli correctly. Although the audio in the scene was rendered with an HRTF, the authors do not describe the implementation of any acoustics from the classroom. The study concludes that the implemented system works as expected and is effective in measuring error rate and reaction time compared to previous versions. [23]. Nevertheless, the test environment does not seem to accurately represent a natural classroom setting, and the absence of any modelling of the room acoustics makes it difficult to conclude whether a test in a real classroom would give different result. The environment seems to have a lot of experimental control, and even though it is successful at collecting data, it may lack ecological validity. Despite these limitations, using simultaneous distracting and target stimuli is an effective method for evaluating selective attention and should also be included in the prototype presented in this paper.

### Ecologically valid hearing research in VR

To enhance the ecological validity of VR environments, Par et al. [8] established a set of three complex auditory-visual virtual environments that provide ecologically valid testing, which can be used in hearing research. One of these environments simulates a pub setting. The paper includes recorded RIRs for several source-listener configurations, so other researchers can acoustically recreate the spaces. The paper includes two scenarios that can be used with the accompanying RIRs. One is a scenario where a waiter approaches the listener to take an order (see figure 2). This scenario matches quite well with having a target sound source (i.e., the waiter) while having distracting sound sources (i.e., surrounding conversations).

As mentioned in section 1, RIRs only correspond to the acoustics for that exact space source-listener configuration. Even though the paper includes several RIRs for different positions, it limits the framework only to be used in that exact environment and using their predetermined positions. Another option is using geometrical modeling instead, which enables acoustic modeling of any 3D scene and source-receiver position. The prototype presented in this paper will be inspired by the natural settings and scenarios presented in [8]; however, it will use methods for geometrical modeling instead to omit limitations from using recorded RIRs.

Figure 1: The virtual classroom used in [23]