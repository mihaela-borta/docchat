reproduced the analysed sound fields, as shown in Fig 1. The layout of the spherical array was specifically designed to provide the best perceptual experience of synthesised SDM-responses originating from residential rooms [19]. The loudspeaker sphere was placed in an anechoic chamber. All speakers were temporally matched by signal delays and their frequency responses were matched to \(\pm\) 1.5 dB.

In order to present the acoustical conditions, 20 s extracts of three programme materials of different nature were selected: (i) anechoic speech [20], (ii) Jennifer Warnes - "Bird On a Wire" (pop) and (iii) Jamiroquai - "Cosmic Girl" (rock). As BAQ was the main task, the selected program material was familiar to the listening panel. Similarly, they were all exposed to the real room beforehand but they were not aware of which sources they were listening to.

#### 2.2.3 Virtual Environment

The goal of the study was to provide, besides a congruent imagery, an experience that participants were familiar with, under a typical listening experiment. Therefore the design of the virtual environment did not attempt to optimally utilise the interaction capacities of VR technology, e.g. new forms of User Interface (UI) and interaction, but it had rather mimicked the current evaluation procedures. This would minimise the learning curve and impact in the experience to the assessors. Due to possible cross-modal interactions [21] that could distort auditory perception [10, 11, 22], it was crucial for the visual model of the room to be spatially accurate. The room and objects were then recreated with a 1:1 scale in the game engine _Unity_. The real and virtual rooms are shown in Fig. 2. However, in order to be able to correctly run the listening test, some modifications were made to the virtual model. Acoustic curtains were included to hide the sources under evaluation without loosing realism, i.e. recreating the same set-up encountered in real world listening tests. Moreover, the sofa of the real room was substituted by a 3D model of the chair in the laboratory, to avoid an incongruence between haptic and visual perception that is known to affect the experience. The Head Mounted Display (HMD) utilised to present the visual rendering was an Oculus Rift with Oculus Touch controllers.

Moreover, the interface was preferable to evoke internal references in order to increase the degree of plausibility, i.e. an interface familiar to participants. To accomplish this, the interaction system designed aimed to recreate the current apparatus and UI used in listening tests by the participants. This entailed a self-controlled and self-paced experiment controlled by a tablet device, following either a multi-stimulus rating[14] or a double blind triple stimulus [23]. Thus, the design and implementation of the UI in VR duplicated this scenario. The user interaction was possible by touching a virtual screen, acting as a tablet, as shown in Figure 3. The interface used for the evaluation of overall experience was based on the same apparatus, with the UI presenting only one rating scale. As it was assumed that assessors may require the stimuli to be available while the overall experience is judged, the interface made available all sources and program materials, labelled as "A-D" and Music 1,2, and Speech.

### _Playback Engine_

The audio processing and the listening test procedure was handled by Max 7, using SPAT 5.0 toolbox for

Fig. 1: Reproduction system, 40.4 loudspeaker array placed in the anechoic chamber.

Fig. 2: On the left, the living room used for the SRIRs, and on the right the visual rendering of it.