* 187the training, listeners were instructed to focus on unique content features or passages of the stories.
* 188After completed training listeners were seated in the loudspeaker environment and introduced to the listening task and the interaction method using the VR controller.
* 190
* 191E. Virtual audio-visual setup
* 192
* 193The virtual visual scenes were rendered on the head-mounted display (HMD) of an HTC Vive Pro
* 194Eye (HTC Vive system, HTC Corporation, New Taipei City, Taiwan). This system allowed to track the listeners motion and record eye gaze and pupil dilation from inside the HMD with a sampling frequency of up to 120 Hz and an accuracy between 0.5\({}^{\circ}\) and 1.1\({}^{\circ}\). The visual virtual
* 197scenes were modeled and displayed using Unity (Unity Technologies, San Francisco, California, USA).
* 199The acoustic scenes were reproduced on 64-channel spherical loudspeaker array housed in an anechoic chamber (see (Ahrens, Marschall, et al., 2019) for details). The loudspeaker signals were generated using the room acoustic simulation using the LoRA-toolbox (Favrot & Buchholz, 2010).
* 202For the loudspeaker playback the nearest loudspeaker mapping was applied, where the direct sound
* 203as well as the early reflections are mapped to the nearest loudspeaker. The late reverberant tail is reproduced using 1\({}^{\text{st}}\) order ambisonics to achieve a diffuse acoustic field (Favrot & Buchholz, 2010).
* 206F. Outcome measures and statistical analyses
* 207
* 208To evaluate the listeners' ability to successfully analyze a cocktail-party scenario, two outcome measures were evaluated. First, the ability to correctly identify and locate the target talker. This